{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d409209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from load_raw_dataset import load_raw_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dff73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install quinine\n",
    "#pip install torchvision\n",
    "#pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a14d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Tuning 38317921 of 102008162 parameters.\n",
      "Starting to compute NTK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 2399/2399 [01:57<00:00, 20.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2399/2399 [00:15<00:00, 152.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 6943/6943 [05:49<00:00, 19.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 6943/6943 [00:41<00:00, 166.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 2909/2909 [02:31<00:00, 19.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2909/2909 [00:19<00:00, 148.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1616/1616 [01:27<00:00, 18.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1616/1616 [00:08<00:00, 189.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from load_raw_dataset import load_raw_dataset\n",
    "\n",
    "root = \"/home/ubuntu\"\n",
    "\n",
    "def compute_eNTK(model, dataset_name, split, subsample_size=500000, seed=123):\n",
    "    \n",
    "    dataset = load_raw_dataset(dataset_name, split)\n",
    "\n",
    "    model.eval()\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    params = list(model.parameters())\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    \n",
    "    random_index = torch.randperm(num_params)[:subsample_size]\n",
    "    \n",
    "    if not os.path.exists(f\"{root}/eNTK-robustness/data/ntk_{dataset_name}_{subsample_size}/{split}\"):\n",
    "        os.system(f\"mkdir {root}/eNTK-robustness/data/ntk_{dataset_name}_{subsample_size}/{split}\")\n",
    "        \n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        model.zero_grad()\n",
    "        model.forward(torch.unsqueeze(dataset[i][0], 0).to(device))[0].backward() #to(device) put in for domainnet\n",
    "        eNTK = []\n",
    "        for idx, param in enumerate(params):\n",
    "            if param.requires_grad: #param.grad is not None:\n",
    "                eNTK.append(param.grad.flatten())\n",
    "        eNTK = torch.cat(eNTK)\n",
    "        #subsampling\n",
    "        ntk_data_point = torch.clone(eNTK[random_index])\n",
    "        torch.save(ntk_data_point, f\"{root}/eNTK-robustness/data/ntk_{dataset_name}_{subsample_size}/{split}/ntk_{i}.pt\")\n",
    "        \n",
    "    labels_dir = f\"{root}/eNTK-robustness/data/ntk_{dataset_name}_{subsample_size}/labels\"\n",
    "    labels_file = f\"{labels_dir}/labels_{split}.pkl\"\n",
    "    store_labels(dataset, labels_dir, labels_file)\n",
    "      \n",
    "def store_labels(raw_dataset, save_dir, save_file):\n",
    "    labels = []\n",
    "    for i in tqdm(range(len(raw_dataset))):\n",
    "        labels.append(raw_dataset[i][1])\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.system(f\"mkdir {save_dir}\")\n",
    "    if not os.path.exists(save_file):\n",
    "        os.system(f\"touch {save_file}\")\n",
    "    pickle.dump(labels, open(save_file, 'wb'))\n",
    "                  \n",
    "\n",
    "#add parser\n",
    "from construct_model import build_model\n",
    "import quinine\n",
    "config_path = f\"{root}/eNTK-robustness/configs/adaptation/domainnet.yaml\"\n",
    "config = quinine.Quinfig(config_path)\n",
    "model = build_model(config)\n",
    "print(\"Starting to compute NTK\")\n",
    "for split in [\"sketch_val\",\"real_val\",\"painting_val\",\"clipart_val\"]:\n",
    "    compute_eNTK(model, \"domainnet\", split)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74490e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_labels = pickle.load(open('/home/ubuntu/eNTK-robustness/data/ntk_domainnet_500000/labels/labels_clipart_val.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456e272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = set()\n",
    "for i in train_labels:\n",
    "    if i not in new_labels:\n",
    "        new_labels.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ab1771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9816417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "mega_kernel = torch.load('/home/ubuntu/eNTK-robustness/data/domainnet_mega_kernel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a0e03d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19404, 5537])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mega_kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e529b395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19404"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5537+2399+6943+2909+1616\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_labels = torch.tensor(pickle.load(open(f\"{labels_root}/labels_train.pkl\", 'rb')))\n",
    "test_labels = {}\n",
    "for test_split in test_splits:\n",
    "    test_labels[test_split] = torch.tensor(pickle.load(open(f\"{labels_root}/labels_{test_split}.pkl\",'rb')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c06beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kernel = mega_kernel[:,:5537]\n",
    "test_splits = [\"sketch_val\",\"real_val\",\"painting_val\",\"clipart_val\"]\n",
    "test_kernels = {}\n",
    "test_kernels[test_splits[0]] = mega_kernel[:,5537:7936]\n",
    "test_kernels[test_splits[1]] = mega_kernel[:,7936:14879]\n",
    "test_kernels[test_splits[2]] = mega_kernel[:,14879:17788]\n",
    "test_kernels[test_splits[3]] = mega_kernel[:,17788:19404]\n",
    "labels_root = f\"{root}/eNTK-robustness/data/ntk_domainnet_500000/labels\"\n",
    "train_labels = torch.tensor(pickle.load(open(f\"{labels_root}/labels_train.pkl\", 'rb')))\n",
    "test_labels = {}\n",
    "for test_split in test_splits:\n",
    "    test_labels[test_split] = torch.tensor(pickle.load(open(f\"{labels_root}/labels_{test_split}.pkl\",'rb')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb8aac1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19404"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5537+2399+6943+2909+1616"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
